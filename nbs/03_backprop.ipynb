{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889bb8df-7271-48dc-be70-1d764cadd669",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Forward and backward passess\n",
    "using gradients in backward propagationn to update weights on a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350877f1-872b-4460-af68-e9d9a7d4e772",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup and getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1963d8e-76b1-4494-b4d7-af3da4081d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate code to load all the relevant libraries and put the data into tensors\n",
    "\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl, numpy as np\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "from fastcore.test import test_close\n",
    "torch.manual_seed(42)\n",
    "\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "torch.set_printoptions(precision=2, linewidth=125, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=125)\n",
    "\n",
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14c27a6f-79a7-42e0-a3b9-7337495f693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d5831f-d719-48e0-bbde-d4ce5c451667",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The basic architecture\n",
    "\n",
    "Using SGD, not cross-entropy and then evaluating the results using MSE. It is a hacky way as proof of concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f52e535-4449-4933-8735-dadc3b1a0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f27fd1f5-a3af-47dc-b511-fba05d670013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden layers (arbitrarily chosen)\n",
    "\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af318355-62c7-4235-9879-681714212cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise all the weights and biases on our new basic neural network\n",
    "\n",
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "673135ff-c37a-421a-8213-a1e514c665e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b): return x@w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dbebb25-9b30-4e99-bf8c-ba60bc84f96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 50])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lin(x_valid, w1, b1)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2522534-b302-4690-8a88-d91e04139d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu function clamping, so changing all values less than zero to zero\n",
    "\n",
    "def relu(x): return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bebe839-4366-4fca-86fb-2124a7a164a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00, 11.87,  0.00,  ...,  5.48,  2.14, 15.30],\n",
       "        [ 5.38, 10.21,  0.00,  ...,  0.88,  0.08, 20.23],\n",
       "        [ 3.31,  0.12,  3.10,  ..., 16.89,  0.00, 24.74],\n",
       "        ...,\n",
       "        [ 4.01, 10.35,  0.00,  ...,  0.23,  0.00, 18.28],\n",
       "        [10.62,  0.00, 10.72,  ...,  0.00,  0.00, 18.23],\n",
       "        [ 2.84,  0.00,  1.43,  ...,  0.00,  5.75,  2.12]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(t)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79297032-855e-4863-bbd0-7957cc1fa0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    return lin(l2, w2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f89c28ac-e2e8-4985-9fcb-3e75a64a9e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(x_valid)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5ebd962-2bc2-4689-8c0e-f71636f4d6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  25.75],\n",
       "        [ -13.06],\n",
       "        [-114.79],\n",
       "        ...,\n",
       "        [ -67.44],\n",
       "        [ -74.48],\n",
       "        [ -60.19]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddffbb7-c1ae-4a48-aaa5-84d6dd205788",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# MSE, defining a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60f364e3-0c9b-4d29-a41d-bb34bd2f46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000]), torch.Size([10000, 1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape, res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61e8bcd7-c863-4ffa-a558-a258055f24cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To subtract these from each other we need to add the index collumn, or use the squeeze method to remove the trailing unit vector\n",
    "res.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cc6f3a0-ba2e-4412-9ea8-d4925609ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn targets of training and validation sets into floats as we are using MSE\n",
    "y_train,y_valid = y_train.float(),y_valid.float()\n",
    "\n",
    "# Make our first set of predictions using our model\n",
    "preds = model(x_train)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a74532a-54ed-42c2-93e8-6ef39241a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ): return (output[:,0]-targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1befbe2-a65a-434b-9659-dce835e1342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4308.76)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e552b-b585-4dff-b28c-4f656c5b18f4",
   "metadata": {},
   "source": [
    "# Gradients and backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a4e17-a4d6-459f-bba8-f3e05e63a471",
   "metadata": {},
   "source": [
    "To do here:\n",
    "- figure out what all the individual lines of code do and why\n",
    "- Experiment with the python debugger \n",
    "import pdb; pdb.set_trace() is the code that places a breakpoint. With this the code stops running and you can use various commands to assess the states of the various variables at that point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9522745-e340-4377-be78-9d045c8146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    inp.g = out.g @ w.t()\n",
    "#     Note that the t() method transposes the tensor\n",
    "    # import pdb; pdb.set_trace()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)\n",
    "    \n",
    "    \n",
    "\n",
    "# def lin_grad(inp, out, w, b):\n",
    "#     # grad of matmul with respect to input\n",
    "#     inp.g = out.g @ w.t()\n",
    "#     w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "#     b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e158912-2de5-4657-a7e5-7ef52629d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, target):\n",
    "    #Forward pass\n",
    "    l1 = lin(inp, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w2, b2)\n",
    "    diff = out[:,0]-target\n",
    "    loss = diff.pow(2).mean() \n",
    "    \n",
    "    #Backward pass\n",
    "    out.g = 2.*diff[:,None] / inp.shape[0]\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    l1.g = (l1>0).float() * l2.g\n",
    "    lin_grad(inp, l1, w1, b1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a42c10d-7918-4199-a5b4-32e01ac40ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f41a65e7-bc94-43f7-92e0-55ddc058a9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lin_grad can also be done using numpy transposing (.T()) and miltiplying\n",
    "\n",
    "def lin_grad(inp, out, w, b):\n",
    "    inp.g = out.g @ w.t()\n",
    "#     Note that the t() method transposes the tensor\n",
    "    # import pdb; pdb.set_trace()\n",
    "    w.g = inp.T@out\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e78a8db2-fbaa-481a-83db-7d628a40ab07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save for testing against later\n",
    "def get_grad(x): return x.g.clone()\n",
    "chks = w1,w2,b1,b2,x_train\n",
    "grads = w1g,w2g,b1g,b2g,ig = tuple(map(get_grad, chks))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34af507c-1a98-4cb1-a0c3-8f6086a5d098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using PyTorch to get gradients and compare\n",
    "\n",
    "def mkgrad(x): return x.clone().requires_grad_(True)\n",
    "ptgrads = w12,w22,b12,b22,xt2 = tuple(map(mkgrad, chks))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23fff1d3-fcb4-4308-98e0-27722d03df71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    l1 = lin(inp, w12, b12)\n",
    "    l2 = relu(l1)\n",
    "    out = lin(l2, w22, b22)\n",
    "    return mse(out, targ)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68c472d0-a7a3-4005-bff7-f7c1334c96c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f88cd7ea-635a-4936-a119-217fc93aba10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for a,b in zip(grads, ptgrads): test_close(a, b.grad, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be78e02-3346-4736-8c05-26b752fe558f",
   "metadata": {},
   "source": [
    "# Refactor model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8754e022-9b06-4a77-9dff-fb1548c22f01",
   "metadata": {},
   "source": [
    "## Layers as classess\n",
    "\n",
    "Here we create classes to perform all the above and refactor them for usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b0ecff3d-25d9-40bf-b9d3-9e4b5339136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d7a50a0-86ca-47c6-8e63-593fcdb2ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Lin():\n",
    "    def __init__(self, w, b): self.w,self.b = w,b\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = lin(inp, self.w, self.b)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = self.inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e08ccc0d-9705-473a-bf4d-df6a676c09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Mse():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp,self.targ = inp,targ\n",
    "        self.out = mse(inp, targ)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "725ea984-d614-4b0c-a8f9-08498b9fee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "587ad4a2-f07c-4044-9c01-027edd554829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2710a35-1d70-4da3-aeb7-a829b2fa38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(x_train, y_train)\n",
    "\n",
    "model = Model(w1, b1, w2, b2)\n",
    "loss = model(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1813071-dde5-4a68-b933-09298a23df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3248c-9a6f-4fda-94b3-6d6d97c9b146",
   "metadata": {},
   "source": [
    "## Module.forward()\n",
    "\n",
    "Here we define a class called \"Module\" that stores all the input saving. \n",
    "This is so that we can use inheritance of this classs to simplify subsequent classess, that they only contain the actual mathematics that is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18320db4-ae34-4232-81e7-1d53eb89d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "\n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)\n",
    "    def bwd(self): raise Exception('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "efaba3e8-a51d-4c4f-94c3-25f631fce24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how much cleaner this function now is\n",
    "\n",
    "class Relu(Module):\n",
    "    def forward(self, inp): return inp.clamp_min(0.)\n",
    "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "226ee0b4-8e61-48b3-857f-3965dbe479b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): self.w,self.b = w,b\n",
    "    def forward(self, inp): return inp@self.w + self.b\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f43bb592-cfa3-4533-a4c7-6fd55d38fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Mse(Module):\n",
    "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
    "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a004cfb8-72d1-41b7-8191-b57e5e7e7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "311abdfc-c45b-45ba-bb58-3fb6eabd759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f0ca246-de11-4d73-8751-29ef07e7483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "209e8c9f-67b2-43dd-987b-2737107efe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(w2g, w2.g, eps=0.01)\n",
    "test_close(b2g, b2.g, eps=0.01)\n",
    "test_close(w1g, w1.g, eps=0.01)\n",
    "test_close(b1g, b1.g, eps=0.01)\n",
    "test_close(ig, x_train.g, eps=0.01)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8576f5-4131-4af2-9b7c-7bfdfb98f51d",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "The Module function is already defined in Pytorch, so now that we've implemented it, we can use PyTorch's version - that is why we don't need to define backward. This version already knows what the derivatives are. F is used as the name of the Module, per convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc36c3ab-3211-4b84-8dfb-b7cb7ba4e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fd10aa5-59f6-41b6-80b2-dd102b16a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(n_in,n_out).requires_grad_()\n",
    "        self.b = torch.zeros(n_out).requires_grad_()\n",
    "    def forward(self, inp): return inp@self.w + self.b    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bd976b9d-8383-4aa1-bc71-534d8ab0e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [Linear(n_in,nh), nn.ReLU(), Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return F.mse_loss(x, targ[:,None])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aca03bbc-180c-45d1-b5bb-d8fbecfc4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)\n",
    "loss = model(x_train, y_train)\n",
    "loss.backward()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e29cdad-17a8-4ee4-ac55-9c43a6b89268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-19.60,  -2.40,  -0.12,   1.99,  12.78, -15.32, -18.45,   0.35,   3.75,  14.67,  10.81,  12.20,  -2.95, -28.33,\n",
       "          0.76,  69.15, -21.86,  49.78,  -7.08,   1.45,  25.20,  11.27, -18.15, -13.13, -17.69, -10.42,  -0.13, -18.89,\n",
       "        -34.81,  -0.84,  40.89,   4.45,  62.35,  31.70,  55.15,  45.13,   3.25,  12.75,  12.45,  -1.41,   4.55,  -6.02,\n",
       "        -62.51,  -1.89,  -1.41,   7.00,   0.49,  18.72,  -4.84,  -6.52])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0 = model.layers[0]\n",
    "l0.b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f87eea-bd17-4825-8413-586517753251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
